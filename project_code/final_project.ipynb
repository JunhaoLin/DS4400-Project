{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS4400 Final Project\n",
    "### Instructor: Ehsan Elhamifar\n",
    "### Team member: Junhao Lin, Minghua Zhang, Mengting Tang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "#Reading the data, using pandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Create a dataset class\n",
    "class dataset(Dataset):\n",
    "  def __init__(self,x,y):\n",
    "    self.x = torch.tensor(x,dtype=torch.float32)\n",
    "    self.y = torch.tensor(y,dtype=torch.float32)\n",
    "    self.length = self.x.shape[0]\n",
    " \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x[idx],self.y[idx]\n",
    "    \n",
    "  def __len__(self):\n",
    "    return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ID', 'Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness', 'Impulsiveness', 'Sensation_seeking', 'Alcohol', 'Amphetamine', 'Amyl_nitrite', 'Benzodiazepine', 'Caffeine', 'Cannabis', 'Chocolate', 'Cocaine', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'Legal_highs', 'LSD', 'Methadone', 'Mushrooms', 'Nicotine', 'Semeron', 'VSA']\n",
    "data = pd.read_csv(\"drug_consumption.data\",header = None, names = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>...</th>\n",
       "      <th>Ecstasy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>Semeron</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.76250</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>-0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>...</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>0.11440</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.78155</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-1.43719</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.49158</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.76250</td>\n",
       "      <td>0.88309</td>\n",
       "      <td>-0.76096</td>\n",
       "      <td>2.33337</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.28519</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.79151</td>\n",
       "      <td>0.32197</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>-0.27607</td>\n",
       "      <td>...</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age   Gender  Education  Country  Ethnicity  Neuroticism  \\\n",
       "ID                                                                   \n",
       "1879 -0.95197 -0.48246   -0.61113 -0.57009    0.12600     -0.05188   \n",
       "1880 -0.07854 -0.48246   -0.61113  0.24923    0.11440     -0.14882   \n",
       "1881 -0.95197 -0.48246   -1.43719 -0.57009   -0.31685      1.49158   \n",
       "1882 -0.95197 -0.48246    0.45468  0.24923   -0.31685     -0.05188   \n",
       "1883 -0.95197 -0.48246   -0.61113 -0.28519   -0.31685     -0.79151   \n",
       "1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685     -1.19430   \n",
       "1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685     -0.24649   \n",
       "1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685      1.13281   \n",
       "1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685      0.91093   \n",
       "1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685     -0.46725   \n",
       "\n",
       "      Extraversion  Openness  Agreeableness  Conscientiousness  ...  Ecstasy  \\\n",
       "ID                                                              ...            \n",
       "1879      -1.76250   0.58331       -0.76096           -0.14277  ...      CL5   \n",
       "1880      -0.57545   1.43533       -0.91699           -0.78155  ...      CL3   \n",
       "1881      -1.92173  -0.58331       -1.77200            0.58489  ...      CL2   \n",
       "1882      -1.76250   0.88309       -0.76096            2.33337  ...      CL0   \n",
       "1883       0.32197   0.29338       -0.30172           -0.27607  ...      CL5   \n",
       "1884       1.74091   1.88511        0.76096           -1.13788  ...      CL0   \n",
       "1885       1.74091   0.58331        0.76096           -1.51840  ...      CL2   \n",
       "1886      -1.37639  -1.27553       -1.77200           -1.38502  ...      CL4   \n",
       "1887      -1.92173   0.29338       -1.62090           -2.57309  ...      CL3   \n",
       "1888       2.12700   1.65653        1.11406            0.41594  ...      CL3   \n",
       "\n",
       "      Heroin Ketamine Legal_highs  LSD Methadone Mushrooms Nicotine Semeron  \\\n",
       "ID                                                                            \n",
       "1879     CL0      CL0         CL2  CL4       CL0       CL4      CL6     CL0   \n",
       "1880     CL0      CL3         CL5  CL3       CL0       CL4      CL2     CL0   \n",
       "1881     CL5      CL0         CL2  CL0       CL6       CL0      CL6     CL0   \n",
       "1882     CL0      CL0         CL2  CL0       CL0       CL2      CL2     CL0   \n",
       "1883     CL2      CL0         CL4  CL5       CL4       CL0      CL6     CL0   \n",
       "1884     CL0      CL0         CL3  CL3       CL0       CL0      CL0     CL0   \n",
       "1885     CL0      CL0         CL3  CL5       CL4       CL4      CL5     CL0   \n",
       "1886     CL0      CL2         CL0  CL2       CL0       CL2      CL6     CL0   \n",
       "1887     CL0      CL0         CL3  CL3       CL0       CL3      CL4     CL0   \n",
       "1888     CL0      CL0         CL3  CL3       CL0       CL3      CL6     CL0   \n",
       "\n",
       "      VSA  \n",
       "ID         \n",
       "1879  CL2  \n",
       "1880  CL2  \n",
       "1881  CL2  \n",
       "1882  CL0  \n",
       "1883  CL1  \n",
       "1884  CL5  \n",
       "1885  CL0  \n",
       "1886  CL0  \n",
       "1887  CL0  \n",
       "1888  CL2  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the 'ID' as the index of the data \n",
    "data.set_index('ID', inplace = True)\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "1       0.49788\n",
       "2      -0.07854\n",
       "3       0.49788\n",
       "4      -0.95197\n",
       "5       0.49788\n",
       "         ...   \n",
       "1884   -0.95197\n",
       "1885   -0.95197\n",
       "1886   -0.07854\n",
       "1887   -0.95197\n",
       "1888   -0.95197\n",
       "Name: Age, Length: 1885, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the age, gender, education, country, and ethnicity columns in the data have been encoded when we extracted them. \n",
    "In order to put them in use, we have to decode them acoording to the instruction provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also need to convert the digits of these values into five decimal places since the orginal ones' is float64 \n",
    "#If we kept float64, the comparsion would not work \n",
    "\n",
    "for term in ['Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Neuroticism',\n",
    "       'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness',\n",
    "       'Impulsiveness', 'Sensation_seeking']:\n",
    "    for value in data[term]:\n",
    "        value = '{:.5f}'.format(value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>...</th>\n",
       "      <th>Ecstasy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>Semeron</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age   Gender  Education  Country  Ethnicity  Neuroticism  \\\n",
       "ID                                                                   \n",
       "1     0.49788  0.48246   -0.05921  0.96082    0.12600      0.31287   \n",
       "2    -0.07854 -0.48246    1.98437  0.96082   -0.31685     -0.67825   \n",
       "3     0.49788 -0.48246   -0.05921  0.96082   -0.31685     -0.46725   \n",
       "4    -0.95197  0.48246    1.16365  0.96082   -0.31685     -0.14882   \n",
       "5     0.49788  0.48246    1.98437  0.96082   -0.31685      0.73545   \n",
       "...       ...      ...        ...      ...        ...          ...   \n",
       "1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685     -1.19430   \n",
       "1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685     -0.24649   \n",
       "1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685      1.13281   \n",
       "1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685      0.91093   \n",
       "1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685     -0.46725   \n",
       "\n",
       "      Extraversion  Openness  Agreeableness  Conscientiousness  ...  Ecstasy  \\\n",
       "ID                                                              ...            \n",
       "1         -0.57545  -0.58331       -0.91699           -0.00665  ...      CL0   \n",
       "2          1.93886   1.43533        0.76096           -0.14277  ...      CL4   \n",
       "3          0.80523  -0.84732       -1.62090           -1.01450  ...      CL0   \n",
       "4         -0.80615  -0.01928        0.59042            0.58489  ...      CL0   \n",
       "5         -1.63340  -0.45174       -0.30172            1.30612  ...      CL1   \n",
       "...            ...       ...            ...                ...  ...      ...   \n",
       "1884       1.74091   1.88511        0.76096           -1.13788  ...      CL0   \n",
       "1885       1.74091   0.58331        0.76096           -1.51840  ...      CL2   \n",
       "1886      -1.37639  -1.27553       -1.77200           -1.38502  ...      CL4   \n",
       "1887      -1.92173   0.29338       -1.62090           -2.57309  ...      CL3   \n",
       "1888       2.12700   1.65653        1.11406            0.41594  ...      CL3   \n",
       "\n",
       "      Heroin Ketamine Legal_highs  LSD Methadone Mushrooms Nicotine Semeron  \\\n",
       "ID                                                                            \n",
       "1        CL0      CL0         CL0  CL0       CL0       CL0      CL2     CL0   \n",
       "2        CL0      CL2         CL0  CL2       CL3       CL0      CL4     CL0   \n",
       "3        CL0      CL0         CL0  CL0       CL0       CL1      CL0     CL0   \n",
       "4        CL0      CL2         CL0  CL0       CL0       CL0      CL2     CL0   \n",
       "5        CL0      CL0         CL1  CL0       CL0       CL2      CL2     CL0   \n",
       "...      ...      ...         ...  ...       ...       ...      ...     ...   \n",
       "1884     CL0      CL0         CL3  CL3       CL0       CL0      CL0     CL0   \n",
       "1885     CL0      CL0         CL3  CL5       CL4       CL4      CL5     CL0   \n",
       "1886     CL0      CL2         CL0  CL2       CL0       CL2      CL6     CL0   \n",
       "1887     CL0      CL0         CL3  CL3       CL0       CL3      CL4     CL0   \n",
       "1888     CL0      CL0         CL3  CL3       CL0       CL3      CL6     CL0   \n",
       "\n",
       "      VSA  \n",
       "ID         \n",
       "1     CL0  \n",
       "2     CL0  \n",
       "3     CL0  \n",
       "4     CL0  \n",
       "5     CL0  \n",
       "...   ...  \n",
       "1884  CL5  \n",
       "1885  CL0  \n",
       "1886  CL0  \n",
       "1887  CL0  \n",
       "1888  CL2  \n",
       "\n",
       "[1885 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to manipulate data and transform them into more understandable formats\n",
    "\n",
    "def decodeAge(age) -> int:\n",
    "    \"\"\"We need to convert age into reasonable and intuitive catagories:\n",
    "        - 0: 18-24\n",
    "        - 1: 25-34\n",
    "        - 2: 35-44\n",
    "        - 3: 45-54\n",
    "        - 4: 55-64\n",
    "        - 5: 65+\n",
    "    \"\"\"\n",
    "    if (age == -0.95197):\n",
    "        age = 0\n",
    "    elif (age == -0.07854):\n",
    "        age = 1\n",
    "    elif (age == 0.49788):\n",
    "        age = 2\n",
    "    elif (age == 1.09449):\n",
    "        age = 3\n",
    "    elif (age == 1.82213):\n",
    "        age = 4\n",
    "    elif (age == 2.59171):\n",
    "        age = 5\n",
    "    return age\n",
    "\n",
    "data['Age'] = data['Age'].map(decodeAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeGender(gender) -> int:\n",
    "    \"\"\"Transform gender into understandable format\n",
    "        - 0: Male\n",
    "        - 1: Female\n",
    "    \"\"\"\n",
    "    if (gender == 0.48246):\n",
    "        gender = 1\n",
    "    elif (gender == -0.48246 ):\n",
    "        gender = 0\n",
    "    return gender\n",
    "\n",
    "data['Gender'] = data['Gender'].map(decodeGender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeEducation(edu) -> int:\n",
    "    \"\"\"Transform education level into understandable format\n",
    "        - 0: Left school before 16 years\n",
    "        - 1: Left school at 16 years\n",
    "        - 2: Left school at 17 years\n",
    "        - 3: Left school at 18 years \n",
    "        - 4: Some college or university, no certificate or degree \n",
    "        - 5: Professional certificate/ diploma   \n",
    "        - 6: University degree \n",
    "        - 7: Masters degree \n",
    "        - 8: Doctorate degree\n",
    "\n",
    "    \"\"\"\n",
    "    if (edu == -2.43591):\n",
    "        edu = 0\n",
    "    elif (edu == -1.73790):\n",
    "        edu = 1\n",
    "    elif (edu == -1.43719):\n",
    "        edu = 2\n",
    "    elif (edu == -1.22751):\n",
    "        edu = 3\n",
    "    elif (edu == -0.61113):\n",
    "        edu = 4\n",
    "    elif (edu == -0.05921):\n",
    "        edu = 5\n",
    "    elif (edu == 0.45468):\n",
    "        edu = 6\n",
    "    elif (edu == 1.16365):\n",
    "        edu = 7\n",
    "    elif (edu == 1.98437):\n",
    "        edu = 8\n",
    "    return edu\n",
    "\n",
    "data['Education'] = data['Education'].map(decodeEducation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeCountry(country): \n",
    "    \"\"\"Transform country of origin into understandable format\n",
    "        - 0: Australia\n",
    "        - 1: Canada\n",
    "        - 2: New Zealand\n",
    "        - 3: Other\n",
    "        - 4: Republic of Ireland\n",
    "        - 5: UK\n",
    "        - 6: USA\n",
    "    \"\"\" \n",
    "    if (country == -0.09765):\n",
    "        country = 0\n",
    "    elif (country == 0.24923):\n",
    "        country = 1\n",
    "    elif (country == -0.46841):\n",
    "        country= 2\n",
    "    elif (country == -0.28519):\n",
    "        country = 3\n",
    "    elif (country == 0.21128):\n",
    "        country = 4\n",
    "    elif (country == 0.96082):\n",
    "        country = 5\n",
    "    elif (country == -0.57009):\n",
    "        country = 6\n",
    "    return country\n",
    "\n",
    "data['Country'] = data['Country'].map(decodeCountry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeEthnicity(eth):\n",
    "    \"\"\"Decode ethnicities into understandable catagories\n",
    "        - 0: Asian\n",
    "        - 1: Black\n",
    "        - 2: Mixed-Black/Asian\n",
    "        - 3: Mixed-White/Asian\n",
    "        - 4: Mixed-White/Black \n",
    "        - 5: Other\n",
    "        - 6: White\n",
    "    \"\"\"\n",
    "    if (eth == -0.50212):\n",
    "        eth = 0\n",
    "    elif (eth == -1.10702):\n",
    "        eth = 1\n",
    "    elif (eth == 1.90725):\n",
    "        eth = 2\n",
    "    elif (eth == 0.12600):\n",
    "        eth = 3\n",
    "    elif (eth == -0.22166):\n",
    "        eth = 4\n",
    "    elif (eth == 0.11440):\n",
    "        eth = 5\n",
    "    elif (eth == -0.31685):\n",
    "        eth = 6\n",
    "    return eth\n",
    "\n",
    "data['Ethnicity'] = data['Ethnicity'].map(decodeEthnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>...</th>\n",
       "      <th>Ecstasy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>Semeron</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age   Gender  Education  Country  Ethnicity  Neuroticism  \\\n",
       "ID                                                                   \n",
       "1     0.49788  0.48246   -0.05921  0.96082        3.0      0.31287   \n",
       "2     1.00000 -0.48246    8.00000  0.96082        6.0     -0.67825   \n",
       "3     0.49788 -0.48246   -0.05921  0.96082        6.0     -0.46725   \n",
       "4    -0.95197  0.48246    7.00000  0.96082        6.0     -0.14882   \n",
       "5     0.49788  0.48246    8.00000  0.96082        6.0      0.73545   \n",
       "...       ...      ...        ...      ...        ...          ...   \n",
       "1884 -0.95197  0.48246   -0.61113  6.00000        6.0     -1.19430   \n",
       "1885 -0.95197 -0.48246   -0.61113  6.00000        6.0     -0.24649   \n",
       "1886  1.00000  0.48246    0.45468  6.00000        6.0      1.13281   \n",
       "1887 -0.95197  0.48246   -0.61113  6.00000        6.0      0.91093   \n",
       "1888 -0.95197 -0.48246   -0.61113  0.21128        6.0     -0.46725   \n",
       "\n",
       "      Extraversion  Openness  Agreeableness  Conscientiousness  ...  Ecstasy  \\\n",
       "ID                                                              ...            \n",
       "1         -0.57545  -0.58331       -0.91699           -0.00665  ...      CL0   \n",
       "2          1.93886   1.43533        0.76096           -0.14277  ...      CL4   \n",
       "3          0.80523  -0.84732       -1.62090           -1.01450  ...      CL0   \n",
       "4         -0.80615  -0.01928        0.59042            0.58489  ...      CL0   \n",
       "5         -1.63340  -0.45174       -0.30172            1.30612  ...      CL1   \n",
       "...            ...       ...            ...                ...  ...      ...   \n",
       "1884       1.74091   1.88511        0.76096           -1.13788  ...      CL0   \n",
       "1885       1.74091   0.58331        0.76096           -1.51840  ...      CL2   \n",
       "1886      -1.37639  -1.27553       -1.77200           -1.38502  ...      CL4   \n",
       "1887      -1.92173   0.29338       -1.62090           -2.57309  ...      CL3   \n",
       "1888       2.12700   1.65653        1.11406            0.41594  ...      CL3   \n",
       "\n",
       "      Heroin Ketamine Legal_highs  LSD Methadone Mushrooms Nicotine Semeron  \\\n",
       "ID                                                                            \n",
       "1        CL0      CL0         CL0  CL0       CL0       CL0      CL2     CL0   \n",
       "2        CL0      CL2         CL0  CL2       CL3       CL0      CL4     CL0   \n",
       "3        CL0      CL0         CL0  CL0       CL0       CL1      CL0     CL0   \n",
       "4        CL0      CL2         CL0  CL0       CL0       CL0      CL2     CL0   \n",
       "5        CL0      CL0         CL1  CL0       CL0       CL2      CL2     CL0   \n",
       "...      ...      ...         ...  ...       ...       ...      ...     ...   \n",
       "1884     CL0      CL0         CL3  CL3       CL0       CL0      CL0     CL0   \n",
       "1885     CL0      CL0         CL3  CL5       CL4       CL4      CL5     CL0   \n",
       "1886     CL0      CL2         CL0  CL2       CL0       CL2      CL6     CL0   \n",
       "1887     CL0      CL0         CL3  CL3       CL0       CL3      CL4     CL0   \n",
       "1888     CL0      CL0         CL3  CL3       CL0       CL3      CL6     CL0   \n",
       "\n",
       "      VSA  \n",
       "ID         \n",
       "1     CL0  \n",
       "2     CL0  \n",
       "3     CL0  \n",
       "4     CL0  \n",
       "5     CL0  \n",
       "...   ...  \n",
       "1884  CL5  \n",
       "1885  CL0  \n",
       "1886  CL0  \n",
       "1887  CL0  \n",
       "1888  CL2  \n",
       "\n",
       "[1885 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we want binary classification, we want to modify orginal data: \n",
    "\n",
    "#### when a person consumed the drug last year, last decade, over a decade ago or never used before, we classifed them as 'non-user' and label them as --  -1 \n",
    "\n",
    "#### otherwise, when a person consumed the drug last month, last week, or last day, we considered them as 'user' of this drug -- +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFre(a):\n",
    "    if ((a == 'CL6') or (a == 'CL5') or (a == 'CL4') ):\n",
    "        a = 1\n",
    "    elif ((a == 'CL0') or (a == 'CL1') or (a == 'CL2') or (a == 'CL3')):\n",
    "        a = -1\n",
    "    \n",
    "    return a\n",
    "\n",
    "for drug in ['Alcohol', 'Amphetamine',\n",
    "       'Amyl_nitrite', 'Benzodiazepine', 'Caffeine', 'Cannabis', 'Chocolate',\n",
    "       'Cocaine', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'Legal_highs',\n",
    "       'LSD', 'Methadone', 'Mushrooms', 'Nicotine', 'Semeron', 'VSA']:\n",
    "    data[drug] = data[drug].map(classifyFre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also classify 18 drugs into three major categories in order to simpify the problem:\n",
    "#notice: some drugs belong to \n",
    "#Heroin, Ecstasy, and Benzodiazepines\n",
    "\n",
    "data['Heroins'] = data.apply(lambda x: int((x['Cocaine'] + x['Crack'] + x['Heroin'] + x['Methadone'])>-4), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Ecstasies'] = data.apply(lambda x: int((x['Amphetamine']  + x['Cannabis'] + x['Cocaine']  + x['Ecstasy'] + x['Ketamine'] + x['LSD'] + x['Methadone'] + x['Mushrooms'] )>-8), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Benzodiazepines'] = data.apply(lambda x: int((x['Amphetamine'] + x['Cocaine'] + x['Methadone'])>-3), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Caffeine','Chocolate','Nicotine','Legal_highs','Alcohol','Amphetamine','Amyl_nitrite','Benzodiazepine', 'Cannabis', 'Cocaine', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'LSD', 'Methadone', 'Mushrooms', 'Semeron', 'VSA'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Impulsiveness</th>\n",
       "      <th>Sensation_seeking</th>\n",
       "      <th>Heroins</th>\n",
       "      <th>Ecstasies</th>\n",
       "      <th>Benzodiazepines</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age   Gender  Education  Country  Ethnicity  Neuroticism  \\\n",
       "ID                                                                 \n",
       "1   0.49788  0.48246   -0.05921  0.96082        3.0      0.31287   \n",
       "2   1.00000 -0.48246    8.00000  0.96082        6.0     -0.67825   \n",
       "3   0.49788 -0.48246   -0.05921  0.96082        6.0     -0.46725   \n",
       "4  -0.95197  0.48246    7.00000  0.96082        6.0     -0.14882   \n",
       "5   0.49788  0.48246    8.00000  0.96082        6.0      0.73545   \n",
       "\n",
       "    Extraversion  Openness  Agreeableness  Conscientiousness  Impulsiveness  \\\n",
       "ID                                                                            \n",
       "1       -0.57545  -0.58331       -0.91699           -0.00665       -0.21712   \n",
       "2        1.93886   1.43533        0.76096           -0.14277       -0.71126   \n",
       "3        0.80523  -0.84732       -1.62090           -1.01450       -1.37983   \n",
       "4       -0.80615  -0.01928        0.59042            0.58489       -1.37983   \n",
       "5       -1.63340  -0.45174       -0.30172            1.30612       -0.21712   \n",
       "\n",
       "    Sensation_seeking  Heroins  Ecstasies  Benzodiazepines  \n",
       "ID                                                          \n",
       "1            -1.18084        0          0                0  \n",
       "2            -0.21575        0          1                0  \n",
       "3             0.40148        0          0                0  \n",
       "4            -1.18084        0          0                0  \n",
       "5            -0.21575        0          0                0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also split the dataset into three parts based on three targets:\n",
    "\n",
    "data1 = data.drop(['Ecstasies', 'Benzodiazepines'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.drop(['Heroins', 'Benzodiazepines'], axis = 1)\n",
    "data3 = data.drop(['Ecstasies', 'Heroins'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into features and target \n",
    "y1 = data1['Heroins']\n",
    "X1 = data1.drop(['Heroins'], axis = 1)\n",
    "\n",
    "y2 = data2['Ecstasies']\n",
    "X2 = data2.drop(['Ecstasies'], axis = 1)\n",
    "\n",
    "y3 = data3['Benzodiazepines']\n",
    "X3 = data3.drop(['Benzodiazepines'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, train_size = 0.8, random_state = 42)\n",
    "#X1_val, X1_test, y1_val, y1_test = train_test_split(X1_rem, y1_rem, train_size = 0.5, random_state = 42)\n",
    "\n",
    "# spliting the data on target ecstasyPl into train and test\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size = 0.8, random_state = 42)\n",
    "#X2_val, X2_test, y2_val, y2_test = train_test_split(X2_rem, y2_rem, train_size = 0.5, random_state = 42)\n",
    "\n",
    "# spliting the data on target benzoPl into train and test\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, train_size = 0.8, random_state = 42)\n",
    "#X3_val, X3_test, y3_val, y3_test = train_test_split(X3_rem, y3_rem, train_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function that train the model by give train data and return the f1 scores for both train set and test set\n",
    "from sklearn import metrics\n",
    "def trainAndEval(model, X_train, y_train, X_test, y_test): \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    test_score = metrics.f1_score(y_test, y_test_pred)\n",
    "    train_score = metrics.f1_score(y_train, y_train_pred)\n",
    "    \n",
    "    return test_score, train_score\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "## Heroins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "clf = LogisticRegression(penalty = 'l2', C=0.01, solver = 'liblinear', class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.4214285714285714\n",
      "test:  0.4390243902439025\n"
     ]
    }
   ],
   "source": [
    "scores = trainAndEval(clf, X1_train, y1_train, X1_test, y1_test)\n",
    "print('train: ', scores[1])\n",
    "print('test: ', scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{'C': [1e-20, 1e-19, 1e-18, 1e-17, 1e-16, 1e-15, 1e-14,\n",
       "                                1e-13, 1e-12, 1e-11, 1e-10, 1e-09, 1e-08, 1e-07,\n",
       "                                1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                100, 1000, 10000, 100000, 1000000],\n",
       "                          'class_weight': ['balanced'], 'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear']}],\n",
       "             scoring='f1', verbose=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = [\n",
    "    \n",
    "    {\n",
    "     'penalty' : ['l1', 'l2'],\n",
    "    'C' : [10**i for i in range(-20,7)],\n",
    "    'solver' : ['liblinear'],\n",
    "     'class_weight': ['balanced']\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "# Finding the best parameters by using Grid Search and cross validation \n",
    "\n",
    "scv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "heroin_GSCV = GridSearchCV(LogisticRegression(), param_grid = param_grid, scoring = 'f1', cv = scv, verbose=True, n_jobs=-1)\n",
    "\n",
    "best_heroin_clf = heroin_GSCV.fit(X1_train, y1_train)\n",
    "\n",
    "best_heroin_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001,\n",
       " 'class_weight': 'balanced',\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_heroin_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.4368932038834951\n",
      "Train Score:  0.423444976076555\n"
     ]
    }
   ],
   "source": [
    "y1_pred_test = best_heroin_clf.best_estimator_.predict(X1_test)\n",
    "print(\"Test Score: \",metrics.f1_score(y1_test, y1_pred_test))\n",
    "y1_pred_train = best_heroin_clf.best_estimator_.predict(X1_train)\n",
    "print(\"Train Score: \",metrics.f1_score(y1_train, y1_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecstasies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{'C': [1e-20, 1e-19, 1e-18, 1e-17, 1e-16, 1e-15, 1e-14,\n",
       "                                1e-13, 1e-12, 1e-11, 1e-10, 1e-09, 1e-08, 1e-07,\n",
       "                                1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                100, 1000, 10000, 100000, 1000000],\n",
       "                          'class_weight': ['balanced'], 'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear']}],\n",
       "             scoring='f1', verbose=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecstasy_GSCV = GridSearchCV(LogisticRegression(), param_grid = param_grid, scoring = 'f1', cv = scv, verbose=True, n_jobs=-1)\n",
    "\n",
    "best_ecstasy_clf = ecstasy_GSCV.fit(X2_train, y2_train)\n",
    "\n",
    "best_ecstasy_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ecstasy_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.8131868131868132\n",
      "Train Score:  0.8126259234385492\n"
     ]
    }
   ],
   "source": [
    "y2_pred_test = best_ecstasy_clf.best_estimator_.predict(X2_test)\n",
    "print(\"Test Score: \",metrics.f1_score(y2_test, y2_pred_test))\n",
    "\n",
    "y2_pred_train = best_ecstasy_clf.best_estimator_.predict(X2_train)\n",
    "print(\"Train Score: \",metrics.f1_score(y2_train, y2_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benzos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{'C': [1e-20, 1e-19, 1e-18, 1e-17, 1e-16, 1e-15, 1e-14,\n",
       "                                1e-13, 1e-12, 1e-11, 1e-10, 1e-09, 1e-08, 1e-07,\n",
       "                                1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                100, 1000, 10000, 100000, 1000000],\n",
       "                          'class_weight': ['balanced'], 'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear']}],\n",
       "             scoring='f1', verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benzo_GSCV = GridSearchCV(LogisticRegression(), param_grid = param_grid, scoring = 'f1', cv = scv, verbose=True, n_jobs=-1)\n",
    "\n",
    "best_benzo_clf = benzo_GSCV.fit(X3_train, y3_train)\n",
    "\n",
    "best_benzo_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_benzo_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.5302325581395348\n",
      "Train Score:  0.522279792746114\n"
     ]
    }
   ],
   "source": [
    "y3_pred_test = best_benzo_clf.best_estimator_.predict(X3_test)\n",
    "print(\"Test Score: \",metrics.f1_score(y3_test, y3_pred_test))\n",
    "\n",
    "y3_pred_train = best_benzo_clf.best_estimator_.predict(X3_train)\n",
    "print(\"Train Score: \",metrics.f1_score(y3_train, y3_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine \n",
    "## Heroins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  40 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   20.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [0, 0.5, 1, 10], 'kernel': ['linear', 'rbf'],\n",
       "                          'random_state': [0]}],\n",
       "             scoring='f1', verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = [\n",
    "    \n",
    "    {\n",
    "     'kernel':['linear','rbf'],\n",
    "    'C' : [0,0.5,1,10],\n",
    "        'random_state': [0]\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "# Finding the best parameters by using Grid Search and cross validation \n",
    "\n",
    "scv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "heroin_GSCV = GridSearchCV(SVC(), param_grid = param_grid, scoring = 'f1', cv = scv, verbose=True, n_jobs=-1)\n",
    "\n",
    "best_heroin_clf = heroin_GSCV.fit(X1_train, y1_train)\n",
    "\n",
    "best_heroin_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf', 'random_state': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_heroin_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.13114754098360656\n",
      "Train Score:  0.13284132841328414\n"
     ]
    }
   ],
   "source": [
    "y1_pred_test = best_heroin_clf.best_estimator_.predict(X1_test)\n",
    "print(\"Test Score: \",metrics.f1_score(y1_test, y1_pred_test))\n",
    "y1_pred_train = best_heroin_clf.best_estimator_.predict(X1_train)\n",
    "print(\"Train Score: \",metrics.f1_score(y1_train, y1_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecstasies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [0, 0.5, 1, 10], 'kernel': ['linear', 'rbf'],\n",
       "                          'random_state': [0]}],\n",
       "             scoring='f1', verbose=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecstasy_GSCV = GridSearchCV(SVC(), param_grid = param_grid, scoring = 'f1', cv = scv, verbose=True, n_jobs=-1)\n",
    "\n",
    "best_ecstasy_clf = ecstasy_GSCV.fit(X2_train, y2_train)\n",
    "\n",
    "best_ecstasy_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'rbf', 'random_state': 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ecstasy_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.8181818181818181\n",
      "Train Score:  0.820754716981132\n"
     ]
    }
   ],
   "source": [
    "y2_pred_test = best_ecstasy_clf.best_estimator_.predict(X2_test)\n",
    "print(\"Test Score: \",metrics.f1_score(y2_test, y2_pred_test))\n",
    "\n",
    "y2_pred_train = best_ecstasy_clf.best_estimator_.predict(X2_train)\n",
    "print(\"Train Score: \",metrics.f1_score(y2_train, y2_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   13.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [0, 0.5, 1, 10], 'kernel': ['linear', 'rbf'],\n",
       "                          'random_state': [0]}],\n",
       "             scoring='f1', verbose=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benzo_GSCV = GridSearchCV(SVC(), param_grid = param_grid, scoring = 'f1', cv = scv, verbose=True, n_jobs=-1)\n",
    "\n",
    "best_benzo_clf = benzo_GSCV.fit(X3_train, y3_train)\n",
    "\n",
    "best_benzo_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf', 'random_state': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_benzo_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.3191489361702128\n",
      "Train Score:  0.42362525458248473\n"
     ]
    }
   ],
   "source": [
    "y3_pred_test = best_benzo_clf.best_estimator_.predict(X3_test)\n",
    "print(\"Test Score: \",metrics.f1_score(y3_test, y3_pred_test))\n",
    "\n",
    "y3_pred_train = best_benzo_clf.best_estimator_.predict(X3_train)\n",
    "print(\"Train Score: \",metrics.f1_score(y3_train, y3_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 40\n",
    "batch_size = 60\n",
    "\n",
    "# load training data\n",
    "trainset1 = dataset(X2_train.to_numpy(), y2_train.to_numpy())\n",
    "trainloader1 = DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "# load testing data\n",
    "testset1 = dataset(X2_test.to_numpy(), y2_test.to_numpy())\n",
    "testloader1 = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "# load training data\n",
    "trainset2 = dataset(X2_train.to_numpy(), y2_train.to_numpy())\n",
    "trainloader2 = DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "# load testing data\n",
    "testset2 = dataset(X2_test.to_numpy(), y2_test.to_numpy())\n",
    "testloader2 = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# load training data\n",
    "trainset3 = dataset(X2_train.to_numpy(), y2_train.to_numpy())\n",
    "trainloader3 = DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "# load testing data\n",
    "testset3 = dataset(X2_test.to_numpy(), y2_test.to_numpy())\n",
    "testloader3 = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a configurable feed-forward network\n",
    "def feedforward_NN(num_input, num_output, num_layer, num_neuron, activation):\n",
    "    \"\"\"A function emcompassing a customizable Pytorch NN\n",
    "    \n",
    "     `Note: The activation function for output layer is always sigmoid function` \n",
    "\n",
    "        - num_input: The amount of input layers, usually the num of feature.\n",
    "        - num_output: The amount of output layers, usually 1 for binary classification\n",
    "        - num_layer: The amount of hidden layers.\n",
    "        - num_neuron: The amount of neuron in each hidden layer\n",
    "        - activation: The activation function to be used in every hidden layer \n",
    "    \"\"\"\n",
    "    if num_layer == 1:\n",
    "        if activation == 'sigmoid':\n",
    "            model = nn.Sequential(nn.Linear(num_input, num_neuron),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(num_neuron, num_output),\n",
    "                                nn.Sigmoid())\n",
    "        elif activation == 'tanh':\n",
    "            model = nn.Sequential(nn.Linear(num_input, num_neuron),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(num_neuron, num_output),\n",
    "                                nn.Sigmoid())\n",
    "        elif activation == 'identity':\n",
    "            model = nn.Sequential(nn.Linear(num_input, num_neuron),\n",
    "                                nn.Identity(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Identity(),\n",
    "                                nn.Linear(num_neuron, num_output),\n",
    "                                nn.Sigmoid())\n",
    "        elif activation == 'relu':\n",
    "            model = nn.Sequential(nn.Linear(num_input, num_neuron),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(num_neuron, num_output),\n",
    "                                nn.Sigmoid())\n",
    "        else: raise RuntimeError('activation can only be one of the following: sigmoid, identity, relu, tanh')\n",
    "    elif num_layer == 2:\n",
    "        if activation == 'sigmoid':\n",
    "            model = nn.Sequential(nn.Linear(num_input, num_neuron),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(num_neuron, num_output),\n",
    "                                nn.Sigmoid())\n",
    "        elif activation == 'tanh':\n",
    "            model = nn.Sequential(nn.Linear(num_input, num_neuron),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(num_neuron, num_output),\n",
    "                                nn.Sigmoid())\n",
    "        elif activation == 'identity':\n",
    "            model = nn.Sequential(nn.Linear(num_input, num_neuron),\n",
    "                                nn.Identity(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Identity(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.Identity(),\n",
    "                                nn.Linear(num_neuron, num_output),\n",
    "                                nn.Sigmoid())\n",
    "        elif activation == 'relu':\n",
    "            model = nn.Sequential(nn.Linear(num_input, num_neuron),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(num_neuron, num_neuron),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(num_neuron, num_output),\n",
    "                                nn.Sigmoid())\n",
    "        else: raise RuntimeError('activation can only be one of the following: sigmoid, identity, relu, tanh')\n",
    "    else: raise RuntimeError('Expected number of layer to be either 1 or 2')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to train the model\n",
    "def train_NN(model, epochs, trainloader, testloader,optimizer, criterion, activation):\n",
    "  \"\"\"Method to train NN\"\"\"\n",
    "\n",
    "  def check_test_accuracy(y_test, y_pred) -> float:\n",
    "    \"\"\"helper method to determine the test accuracy by comparing test data and predicted data\"\"\"\n",
    "    counter = 0\n",
    "    for y1, y2 in zip(y_test, y_pred):\n",
    "      if y2 > 0.5 and y1 == 0:\n",
    "        counter += 1\n",
    "      if y2 <= 0.5 and y1 == 1:\n",
    "        counter += 1\n",
    "    \n",
    "    return (len(y_test) - counter) / len(y_pred)\n",
    "\n",
    "  print(f\"Current setting: activation function for hidden layer:{activation}, activation function for output layer: Sigmoid.\")\n",
    "\n",
    "  # Train data\n",
    "  # forward loop\n",
    "  for epoch in range(epochs):\n",
    "    # train data\n",
    "    print(f\"----------Epoch {epoch + 1}----------\")\n",
    "    running_loss = 0.0\n",
    "    for x_train, y_train in trainloader:\n",
    "      # Training pass\n",
    "      optimizer.zero_grad()\n",
    "      #print(y_train)\n",
    "      output = model(x_train)\n",
    "      #print(output)\n",
    "      loss = criterion(output, y_train.reshape(-1,1))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "    else:\n",
    "      print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "\n",
    "    #test data\n",
    "    with torch.no_grad():\n",
    "      for x_test, y_test in testloader:\n",
    "        output2 = model(x_test)\n",
    "\n",
    "    # display training error\n",
    "    Training_accuracy = check_test_accuracy(y_train, output)\n",
    "    # displaing testing error\n",
    "    Testing_accuracy = check_test_accuracy(y_test, output2)\n",
    "    print(f\"Training error is {(1-Training_accuracy)*100}%\")\n",
    "    print(f\"Testing error is {(1-Testing_accuracy)}%\")\n",
    "\n",
    "  return model\n",
    "  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current setting: activation function for hidden layer:relu, activation function for output layer: Sigmoid.\n",
      "----------Epoch 1----------\n",
      "Training loss: 0.3947456312867311\n",
      "Training error is 0.0%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 2----------\n",
      "Training loss: 0.39349570125341415\n",
      "Training error is 0.0%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 3----------\n",
      "Training loss: 0.40443750069691586\n",
      "Training error is 12.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 4----------\n",
      "Training loss: 0.39156631666880387\n",
      "Training error is 0.0%\n",
      "Testing error is 0.05882352941176472%\n",
      "----------Epoch 5----------\n",
      "Training loss: 0.41127654967399746\n",
      "Training error is 37.5%\n",
      "Testing error is 0.23529411764705888%\n",
      "----------Epoch 6----------\n",
      "Training loss: 0.3953288294948064\n",
      "Training error is 12.5%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 7----------\n",
      "Training loss: 0.3890306634398607\n",
      "Training error is 0.0%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 8----------\n",
      "Training loss: 0.4117844712275725\n",
      "Training error is 50.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 9----------\n",
      "Training loss: 0.4052788798625653\n",
      "Training error is 25.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 10----------\n",
      "Training loss: 0.3905882703570219\n",
      "Training error is 0.0%\n",
      "Testing error is 0.0%\n",
      "----------Epoch 11----------\n",
      "Training loss: 0.4051597680036838\n",
      "Training error is 25.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 12----------\n",
      "Training loss: 0.4048635180179889\n",
      "Training error is 37.5%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 13----------\n",
      "Training loss: 0.39241558141433275\n",
      "Training error is 25.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 14----------\n",
      "Training loss: 0.40309447336655396\n",
      "Training error is 25.0%\n",
      "Testing error is 0.23529411764705888%\n",
      "----------Epoch 15----------\n",
      "Training loss: 0.39281958685471463\n",
      "Training error is 25.0%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 16----------\n",
      "Training loss: 0.39496674216710603\n",
      "Training error is 25.0%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 17----------\n",
      "Training loss: 0.38998687725800735\n",
      "Training error is 12.5%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 18----------\n",
      "Training loss: 0.3919652293507869\n",
      "Training error is 12.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 19----------\n",
      "Training loss: 0.39609435544564175\n",
      "Training error is 25.0%\n",
      "Testing error is 0.05882352941176472%\n",
      "----------Epoch 20----------\n",
      "Training loss: 0.39053658969127214\n",
      "Training error is 25.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 21----------\n",
      "Training loss: 0.38528721550336253\n",
      "Training error is 0.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 22----------\n",
      "Training loss: 0.3789480815713222\n",
      "Training error is 0.0%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 23----------\n",
      "Training loss: 0.3944280594587326\n",
      "Training error is 37.5%\n",
      "Testing error is 0.23529411764705888%\n",
      "----------Epoch 24----------\n",
      "Training loss: 0.3881423301421679\n",
      "Training error is 12.5%\n",
      "Testing error is 0.05882352941176472%\n",
      "----------Epoch 25----------\n",
      "Training loss: 0.38608597677487594\n",
      "Training error is 12.5%\n",
      "Testing error is 0.23529411764705888%\n",
      "----------Epoch 26----------\n",
      "Training loss: 0.382901573410401\n",
      "Training error is 12.5%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 27----------\n",
      "Training loss: 0.3778371037198947\n",
      "Training error is 0.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 28----------\n",
      "Training loss: 0.3853397879462976\n",
      "Training error is 12.5%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 29----------\n",
      "Training loss: 0.3882975119810838\n",
      "Training error is 25.0%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 30----------\n",
      "Training loss: 0.37876788584085613\n",
      "Training error is 12.5%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 31----------\n",
      "Training loss: 0.37461203508652174\n",
      "Training error is 0.0%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 32----------\n",
      "Training loss: 0.38435845994032347\n",
      "Training error is 25.0%\n",
      "Testing error is 0.05882352941176472%\n",
      "----------Epoch 33----------\n",
      "Training loss: 0.3805805186812694\n",
      "Training error is 12.5%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 34----------\n",
      "Training loss: 0.3814905801644692\n",
      "Training error is 25.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 35----------\n",
      "Training loss: 0.38150223745749545\n",
      "Training error is 0.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 36----------\n",
      "Training loss: 0.37118634352317226\n",
      "Training error is 0.0%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 37----------\n",
      "Training loss: 0.37027110216709286\n",
      "Training error is 0.0%\n",
      "Testing error is 0.11764705882352944%\n",
      "----------Epoch 38----------\n",
      "Training loss: 0.3750204203220514\n",
      "Training error is 12.5%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 39----------\n",
      "Training loss: 0.3829570687734164\n",
      "Training error is 25.0%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 40----------\n",
      "Training loss: 0.3797392575786664\n",
      "Training error is 12.5%\n",
      "Testing error is 0.23529411764705888%\n"
     ]
    }
   ],
   "source": [
    "model = feedforward_NN(num_input=12, num_output=1, num_layer=2, num_neuron=20, activation='relu')\n",
    "\n",
    "optimizer = torch.optim.Adam(model1.parameters(),lr=learning_rate)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "trained_model1 = train_NN(model1, epochs, trainloader1, testloader1,optimizer, criterion, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecstasies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current setting: activation function for hidden layer:relu, activation function for output layer: Sigmoid.\n",
      "----------Epoch 1----------\n",
      "Training loss: 0.6980004814954904\n",
      "Training error is 37.5%\n",
      "Testing error is 0.6470588235294117%\n",
      "----------Epoch 2----------\n",
      "Training loss: 0.6976538369288812\n",
      "Training error is 37.5%\n",
      "Testing error is 0.5882352941176471%\n",
      "----------Epoch 3----------\n",
      "Training loss: 0.6975819628972274\n",
      "Training error is 37.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 4----------\n",
      "Training loss: 0.6966731364910419\n",
      "Training error is 12.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 5----------\n",
      "Training loss: 0.6968997373030736\n",
      "Training error is 25.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 6----------\n",
      "Training loss: 0.6981801092624664\n",
      "Training error is 50.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 7----------\n",
      "Training loss: 0.6986887730084933\n",
      "Training error is 62.5%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 8----------\n",
      "Training loss: 0.6985536882510552\n",
      "Training error is 50.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 9----------\n",
      "Training loss: 0.6975708901882172\n",
      "Training error is 37.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 10----------\n",
      "Training loss: 0.6975756516823401\n",
      "Training error is 37.5%\n",
      "Testing error is 0.5882352941176471%\n",
      "----------Epoch 11----------\n",
      "Training loss: 0.6975386349054483\n",
      "Training error is 37.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 12----------\n",
      "Training loss: 0.6978050424502447\n",
      "Training error is 37.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 13----------\n",
      "Training loss: 0.69647544163924\n",
      "Training error is 12.5%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 14----------\n",
      "Training loss: 0.6981264788370866\n",
      "Training error is 50.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 15----------\n",
      "Training loss: 0.6983205584379343\n",
      "Training error is 50.0%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 16----------\n",
      "Training loss: 0.6977703273296356\n",
      "Training error is 37.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 17----------\n",
      "Training loss: 0.69913473037573\n",
      "Training error is 62.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 18----------\n",
      "Training loss: 0.6973822437799894\n",
      "Training error is 37.5%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 19----------\n",
      "Training loss: 0.6982298722633948\n",
      "Training error is 50.0%\n",
      "Testing error is 0.6470588235294117%\n",
      "----------Epoch 20----------\n",
      "Training loss: 0.698243668446174\n",
      "Training error is 50.0%\n",
      "Testing error is 0.5882352941176471%\n",
      "----------Epoch 21----------\n",
      "Training loss: 0.6995502802041861\n",
      "Training error is 75.0%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 22----------\n",
      "Training loss: 0.697417153761937\n",
      "Training error is 37.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 23----------\n",
      "Training loss: 0.6995258400073419\n",
      "Training error is 75.0%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 24----------\n",
      "Training loss: 0.6975314250359168\n",
      "Training error is 37.5%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 25----------\n",
      "Training loss: 0.6995188685563895\n",
      "Training error is 75.0%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 26----------\n",
      "Training loss: 0.6976811862908877\n",
      "Training error is 37.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 27----------\n",
      "Training loss: 0.699657712991421\n",
      "Training error is 75.0%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 28----------\n",
      "Training loss: 0.699528877551739\n",
      "Training error is 75.0%\n",
      "Testing error is 0.6470588235294117%\n",
      "----------Epoch 29----------\n",
      "Training loss: 0.6989834216924814\n",
      "Training error is 62.5%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 30----------\n",
      "Training loss: 0.6981594012333796\n",
      "Training error is 50.0%\n",
      "Testing error is 0.23529411764705888%\n",
      "----------Epoch 31----------\n",
      "Training loss: 0.6986167385027959\n",
      "Training error is 62.5%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 32----------\n",
      "Training loss: 0.6981618243914384\n",
      "Training error is 50.0%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 33----------\n",
      "Training loss: 0.6982996051128094\n",
      "Training error is 50.0%\n",
      "Testing error is 0.5882352941176471%\n",
      "----------Epoch 34----------\n",
      "Training loss: 0.6988030740847955\n",
      "Training error is 62.5%\n",
      "Testing error is 0.5882352941176471%\n",
      "----------Epoch 35----------\n",
      "Training loss: 0.697299987077713\n",
      "Training error is 25.0%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 36----------\n",
      "Training loss: 0.6980720529189477\n",
      "Training error is 50.0%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 37----------\n",
      "Training loss: 0.6989413568606744\n",
      "Training error is 62.5%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 38----------\n",
      "Training loss: 0.6968505130364344\n",
      "Training error is 25.0%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 39----------\n",
      "Training loss: 0.6987605049059942\n",
      "Training error is 62.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 40----------\n",
      "Training loss: 0.6972881418008071\n",
      "Training error is 25.0%\n",
      "Testing error is 0.4117647058823529%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trained_model2 = train_NN(model, epochs, trainloader2, testloader2,optimizer, criterion, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benzos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current setting: activation function for hidden layer:relu, activation function for output layer: Sigmoid.\n",
      "----------Epoch 1----------\n",
      "Training loss: 0.6986997379706457\n",
      "Training error is 62.5%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 2----------\n",
      "Training loss: 0.6988637974629035\n",
      "Training error is 62.5%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 3----------\n",
      "Training loss: 0.69844117302161\n",
      "Training error is 50.0%\n",
      "Testing error is 0.23529411764705888%\n",
      "----------Epoch 4----------\n",
      "Training loss: 0.6976199700282171\n",
      "Training error is 37.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 5----------\n",
      "Training loss: 0.6983331648203043\n",
      "Training error is 50.0%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 6----------\n",
      "Training loss: 0.6986960608225602\n",
      "Training error is 62.5%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 7----------\n",
      "Training loss: 0.6985684014283694\n",
      "Training error is 50.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 8----------\n",
      "Training loss: 0.6989853152861962\n",
      "Training error is 62.5%\n",
      "Testing error is 0.5882352941176471%\n",
      "----------Epoch 9----------\n",
      "Training loss: 0.6999066632527572\n",
      "Training error is 87.5%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 10----------\n",
      "Training loss: 0.6988237339716691\n",
      "Training error is 62.5%\n",
      "Testing error is 0.17647058823529416%\n",
      "----------Epoch 11----------\n",
      "Training loss: 0.6981506920777835\n",
      "Training error is 50.0%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 12----------\n",
      "Training loss: 0.6975533182804401\n",
      "Training error is 37.5%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 13----------\n",
      "Training loss: 0.6991936679069812\n",
      "Training error is 62.5%\n",
      "Testing error is 0.6470588235294117%\n",
      "----------Epoch 14----------\n",
      "Training loss: 0.6996601957541245\n",
      "Training error is 75.0%\n",
      "Testing error is 0.5882352941176471%\n",
      "----------Epoch 15----------\n",
      "Training loss: 0.6982762079972488\n",
      "Training error is 50.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 16----------\n",
      "Training loss: 0.6989346513381371\n",
      "Training error is 62.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 17----------\n",
      "Training loss: 0.6994237899780273\n",
      "Training error is 75.0%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 18----------\n",
      "Training loss: 0.6996943858953623\n",
      "Training error is 75.0%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 19----------\n",
      "Training loss: 0.6974715957274804\n",
      "Training error is 37.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 20----------\n",
      "Training loss: 0.7001761794090271\n",
      "Training error is 87.5%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 21----------\n",
      "Training loss: 0.6992997733446268\n",
      "Training error is 62.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 22----------\n",
      "Training loss: 0.6984595312522008\n",
      "Training error is 50.0%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 23----------\n",
      "Training loss: 0.6977342298397651\n",
      "Training error is 37.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 24----------\n",
      "Training loss: 0.69886514544487\n",
      "Training error is 62.5%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 25----------\n",
      "Training loss: 0.6993578695333921\n",
      "Training error is 75.0%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 26----------\n",
      "Training loss: 0.6981294613618118\n",
      "Training error is 50.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 27----------\n",
      "Training loss: 0.6988706817993751\n",
      "Training error is 62.5%\n",
      "Testing error is 0.7058823529411764%\n",
      "----------Epoch 28----------\n",
      "Training loss: 0.6983659404974717\n",
      "Training error is 50.0%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 29----------\n",
      "Training loss: 0.6991053521633148\n",
      "Training error is 62.5%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 30----------\n",
      "Training loss: 0.6989725621847006\n",
      "Training error is 62.5%\n",
      "Testing error is 0.6470588235294117%\n",
      "----------Epoch 31----------\n",
      "Training loss: 0.698883049763166\n",
      "Training error is 62.5%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 32----------\n",
      "Training loss: 0.6986956665149102\n",
      "Training error is 62.5%\n",
      "Testing error is 0.3529411764705882%\n",
      "----------Epoch 33----------\n",
      "Training loss: 0.698637265425462\n",
      "Training error is 50.0%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 34----------\n",
      "Training loss: 0.6980467278223771\n",
      "Training error is 50.0%\n",
      "Testing error is 0.5294117647058824%\n",
      "----------Epoch 35----------\n",
      "Training loss: 0.697086723951193\n",
      "Training error is 25.0%\n",
      "Testing error is 0.2941176470588235%\n",
      "----------Epoch 36----------\n",
      "Training loss: 0.697963148355484\n",
      "Training error is 50.0%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 37----------\n",
      "Training loss: 0.69954602764203\n",
      "Training error is 75.0%\n",
      "Testing error is 0.4117647058823529%\n",
      "----------Epoch 38----------\n",
      "Training loss: 0.6977831927629617\n",
      "Training error is 37.5%\n",
      "Testing error is 0.47058823529411764%\n",
      "----------Epoch 39----------\n",
      "Training loss: 0.6981929334310385\n",
      "Training error is 50.0%\n",
      "Testing error is 0.6470588235294117%\n",
      "----------Epoch 40----------\n",
      "Training loss: 0.6983013382324805\n",
      "Training error is 50.0%\n",
      "Testing error is 0.2941176470588235%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trained_model3 = train_NN(model, epochs, trainloader3, testloader3,optimizer, criterion, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
